{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(Left.objpoints, Left.imgpoints, img_size,None,None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "  \n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(calibration_folder):\n",
    "\n",
    "    #Initialize object and image points\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = []\n",
    "    images = glob.glob(calibration_folder)\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        if ret == True:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "    return  objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_thresh(img):\n",
    "    img = np.copy(img)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = gaussian_blur(gray, 5)\n",
    "    \n",
    "    #magnitude\n",
    "    abs_sobel_x = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=11))\n",
    "    abs_sobel_y = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=11))\n",
    "    abs_sobelxy = np.sqrt((abs_sobel_x * abs_sobel_x)+(abs_sobel_y * abs_sobel_y))\n",
    "    scaled_mag = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "    mag_binary = np.zeros_like(scaled_mag)\n",
    "    mag_binary[(scaled_mag >= 60) & (scaled_mag <=255)] = 1\n",
    "    \n",
    "    return mag_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_thresh(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=11)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=11)\n",
    "    \n",
    "    abs_grad_dir = np.arctan2(np.absolute(sobel_y), np.absolute(sobel_x))\n",
    "    dir_binary =  np.zeros_like(abs_grad_dir)\n",
    "    dir_binary[(abs_grad_dir >= .7) & (abs_grad_dir <= 1.3)] = 1\n",
    "                                          \n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_threshold_LUV(img,threshold_range):\n",
    "    \n",
    "    l_channel_luv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)[:,:,0]\n",
    "\n",
    "    \n",
    "    l_binary = np.zeros_like(l_channel_luv)\n",
    "    l_binary[(l_channel_luv >= threshold_range[0]) & (l_channel_luv <= threshold_range[1])] = 1\n",
    "    \n",
    "    return l_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_threshold_YCrCb(img,threshold_range):\n",
    "    brightYCB = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)[:,:,0]\n",
    "    \n",
    "    ycrcb_binary = np.zeros_like(brightYCB)\n",
    "    ycrcb_binary[(brightYCB >= threshold_range[0]) & (brightYCB <= threshold_range[1])] = 1\n",
    "    \n",
    "    return ycrcb_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_threshold_LAB(img,threshold_range):\n",
    "    \n",
    "    b_channel_lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)[:,:,2]\n",
    "        \n",
    "    b_binary = np.zeros_like(b_channel_lab)\n",
    "    b_binary[(b_channel_lab >= threshold_range[0]) & (b_channel_lab <= threshold_range[1])] = 1\n",
    "    \n",
    "    return b_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_x(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    \n",
    "    abs_sobelx = np.absolute(sobel_x)\n",
    "    scaled_sobelx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    sobel_x_binary = np.zeros_like(scaled_sobelx)\n",
    "    sobel_x_binary[(scaled_sobelx >= 15) & (scaled_sobelx <= 255)] = 1\n",
    "    \n",
    "    return sobel_x_binary\n",
    "\n",
    "\n",
    "def sobel_y(img):  \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    \n",
    "    abs_sobely = np.absolute(sobel_y)\n",
    "    scaled_sobely = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "    sobel_y_binary = np.zeros_like(scaled_sobely)\n",
    "    sobel_y_binary[(scaled_sobely >= 35) & (scaled_sobely <= 255)] = 1\n",
    "    \n",
    "    return sobel_y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_threshold(img):\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel > 60) & (s_channel <= 255)] = 1\n",
    "    \n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    v_channel = hsv[:,:,2]\n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel >120) & (v_channel <= 255)] = 1 \n",
    "    \n",
    "    \n",
    "    color_binary = np.zeros_like(s_channel)\n",
    "    color_binary[(s_binary == 1) & (v_binary == 1)] = 1\n",
    "    return color_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_video_hard(img):\n",
    "    sobel_x_binary = sobel_x(img)\n",
    "    sobel_y_binary = sobel_y(img)\n",
    "    \n",
    "    mag_binary = magnitude_thresh(img)\n",
    "    dir_binary = direction_thresh(img)\n",
    "    \n",
    "    color_binary = color_threshold(img)\n",
    "    \n",
    "    result_lab = channel_threshold_LAB(img, (145,200))\n",
    "    result_luv = channel_threshold_LUV(img, (215,255))\n",
    "    \n",
    "    hard_output = np.zeros_like(sobel_x_binary)\n",
    "    hard_output[(result_lab == 1) | (result_luv == 1)] = 1\n",
    "    return hard_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_prespective(img):\n",
    "    \n",
    "    #changed transformed precpective\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    src1 = (490, 482) \n",
    "    scr2 = (810, 482)\n",
    "    src3 = (1250, img.shape[0])\n",
    "    src4 = (0, img.shape[0])\n",
    "    src_points = np.array([[src1, scr2, src3, src4]]).astype('float32')\n",
    "    \n",
    "    dst1 = (0, 0)         \n",
    "    dst2 = (1280, 0) \n",
    "    dst3 = (1250, img.shape[0])\n",
    "    dst4 = (40, img.shape[0]) \n",
    "    dst_points = np.array([[dst1, dst2, dst3, dst4]]).astype('float32')\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    Minv = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "    return cv2.warpPerspective(img, M, img_size),Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels_vid(combined_binary_img):\n",
    "    \n",
    "    x, y = np.nonzero(np.transpose(combined_binary_img)) \n",
    "\n",
    "    if Left.found == True: # Find the left lane pixels around previous polynomial\n",
    "        left_x, left_y, Left.found = Left.targeted_search(x, y)\n",
    "        \n",
    "    if Right.found == True: # S Find the right lane pixels around previous polynomial\n",
    "        right_x, right_y, Right.found = Right.targeted_search(x, y)\n",
    "\n",
    "            \n",
    "    if Right.found == False: # Perform blind search for right lane lines\n",
    "        right_x, right_y, Right.found = Right.random_search(x, y, combined_binary_img)\n",
    "            \n",
    "    if Left.found == False:# Perform blind search for left lane lines\n",
    "        left_x, left_y, Left.found = Left.random_search(x, y, combined_binary_img)\n",
    "\n",
    "    left_y = np.array(left_y).astype(np.float32)\n",
    "    left_x = np.array(left_x).astype(np.float32)\n",
    "    right_y = np.array(right_y).astype(np.float32)\n",
    "    right_x = np.array(right_x).astype(np.float32)\n",
    "    \n",
    "    return left_y, left_x, right_y, right_x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial_vid(left_y, left_x, right_y, right_x):\n",
    "\n",
    "    left_fit = np.polyfit(left_y, left_x, 2)\n",
    "    \n",
    "    # Find intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    left_x_int, left_top = Left.find_intercepts(left_fit)\n",
    "    \n",
    "    # Average intercepts across 'n' frames\n",
    "    Left.x_int.append(left_x_int)\n",
    "    Left.top.append(left_top)\n",
    "    left_x_int = np.mean(Left.x_int)\n",
    "    left_top = np.mean(Left.top)\n",
    "    Left.lastx_int = left_x_int\n",
    "    Left.last_top = left_top\n",
    "    \n",
    "    # Add averaged intercepts to current x and y vals\n",
    "    left_x = np.append(left_x, left_x_int)\n",
    "    left_y = np.append(left_y, 720)\n",
    "    left_x = np.append(left_x, left_top)\n",
    "    left_y = np.append(left_y, 0)\n",
    "    \n",
    "    # Sort the detected pixels based on the y-vals\n",
    "    left_x, left_y = Left.sort_values(left_x, left_y)\n",
    "    \n",
    "    Left.X = left_x\n",
    "    Left.Y = left_y\n",
    "    \n",
    "    # Re-calculate polynomial with intercepts and average across 'n' frames\n",
    "    left_fit = np.polyfit(left_y, left_x, 2)\n",
    "    Left.fit0.append(left_fit[0])\n",
    "    Left.fit1.append(left_fit[1])\n",
    "    Left.fit2.append(left_fit[2])\n",
    "    left_fit = [np.mean(Left.fit0), np.mean(Left.fit1), np.mean(Left.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    left_fit_x = left_fit[0]*left_y**2 + left_fit[1]*left_y + left_fit[2]\n",
    "    Left.fitx = left_fit_x\n",
    "    \n",
    "    # Find right polynomial fit based on detected pixels\n",
    "    right_fit = np.polyfit(right_y, right_x, 2)\n",
    "\n",
    "    # Find intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    right_x_int, right_top = Right.find_intercepts(right_fit)\n",
    "    \n",
    "    # Avg. the intercepts across 5 frames\n",
    "    Right.x_int.append(right_x_int)\n",
    "    right_x_int = np.mean(Right.x_int)\n",
    "    Right.top.append(right_top)\n",
    "    right_top = np.mean(Right.top)\n",
    "    Right.lastx_int = right_x_int\n",
    "    Right.last_top = right_top\n",
    "    right_x = np.append(right_x, right_x_int)\n",
    "    right_y = np.append(right_y, 720)\n",
    "    right_x = np.append(right_x, right_top)\n",
    "    right_y = np.append(right_y, 0)\n",
    "    \n",
    "    # Sort right lane pixels\n",
    "    right_x, right_y = Right.sort_values(right_x, right_y)\n",
    "    Right.X = right_x\n",
    "    Right.Y = right_y\n",
    "    \n",
    "    # Re-calculate polynomial with intercepts and average across 'n' frames\n",
    "    right_fit = np.polyfit(right_y, right_x, 2)\n",
    "    Right.fit0.append(right_fit[0])\n",
    "    Right.fit1.append(right_fit[1])\n",
    "    Right.fit2.append(right_fit[2])\n",
    "    right_fit = [np.mean(Right.fit0), np.mean(Right.fit1), np.mean(Right.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    right_fitx = right_fit[0]*right_y**2 + right_fit[1]*right_y + right_fit[2]\n",
    "    Right.fitx = right_fitx\n",
    "    \n",
    "    return right_fitx, left_fit_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center_offset(binary_warped,left_fit,right_fit):\n",
    "    \n",
    "    bottom_y = binary_warped.shape[0] - 1\n",
    "    bottom_x_left = left_fit[0]*(bottom_y**2) + left_fit[1]*bottom_y + left_fit[2]\n",
    "    bottom_x_right = right_fit[0]*(bottom_y**2) + right_fit[1]*bottom_y + right_fit[2]\n",
    "    offset = binary_warped.shape[1]/2 - (bottom_x_left + bottom_x_right)/2\n",
    "\n",
    "    #pixel meter converstion\n",
    "    offset *= 3.7/700\n",
    "    \n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_radius(y_max):\n",
    "\n",
    "    # meters space conversion\n",
    "    y_pixel2m = 30/720\n",
    "    x_pixel2m = 3.7/700\n",
    "\n",
    "    \n",
    "    leftx = Left.X\n",
    "    lefty = Left.Y\n",
    "    rightx = Right.X\n",
    "    righty = Right.Y\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_curve_m = np.polyfit(lefty*y_pixel2m, leftx*y_pixel2m, 2)\n",
    "    right_curve_m = np.polyfit(righty*x_pixel2m, rightx*x_pixel2m, 2)\n",
    "    \n",
    "    # Calculate the new radius for the curve\n",
    "    left_curve_radius = ((1 + (2*left_curve_m[0]*y_max*y_pixel2m + left_curve_m[1])**2)**1.5) / np.absolute(2*left_curve_m[0])\n",
    "    right_curve_radius = ((1 + (2*right_curve_m[0]*y_max*y_pixel2m + right_curve_m[1])**2)**1.5) / np.absolute(2*right_curve_m[0])\n",
    "\n",
    "\n",
    "    return left_curve_radius, right_curve_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lane_Area_Vid(binary_warped, undistorted, left_fitx, right_fitx, m_inv,avg_radius):\n",
    "\n",
    "    #create lane area mask\n",
    "    temp_lane_area = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warped = np.dstack((temp_lane_area, temp_lane_area, temp_lane_area))\n",
    "\n",
    "     #find offset\n",
    "    center_offset = find_center_offset(binary_warped, left_fitx,right_fitx)\n",
    "    \n",
    "\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([left_fitx, Left.Y])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, Right.Y]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warped, np.int_([pts]), isClosed=False, color=(0,0,0), thickness = 40)\n",
    "\n",
    "     #fill green color\n",
    "    cv2.fillPoly(color_warped, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Highlight lane area mask in undistorted\n",
    "    inverse_transformed = cv2.warpPerspective(color_warped, m_inv, (undistorted.shape[1], undistorted.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    lane_area = cv2.addWeighted(undistorted, 1, inverse_transformed, 0.5, 0)\n",
    "\n",
    "    # Write text in image\n",
    "    radius_text = 'Radius of curve is ' + str(round(avg_radius, 2)) + ' m' \n",
    "                      \n",
    "    lane_area = cv2.putText(lane_area, radius_text, (450,40), 0, 1, (0,0,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return lane_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None # fit values position in xaxis\n",
    "        self.Y = None # fit values position in yaxis\n",
    "        calibration_folder ='camera_cal/calibration*.jpg'\n",
    "        self.objpoints, self.imgpoints = calibrate_camera(calibration_folder)\n",
    "        self.found = False  \n",
    "        \n",
    "        # Store recent polynomial coefficients for averaging across frames\n",
    "        self.fit0 = deque(maxlen=10)\n",
    "        self.fit1 = deque(maxlen=10)\n",
    "        self.fit2 = deque(maxlen=10)\n",
    "        \n",
    "        self.fitx = None\n",
    "        \n",
    "        # Keep recent 'x' intercepts avg. across frames\n",
    "        self.x_int = deque(maxlen=10)\n",
    "        self.top = deque(maxlen=10)\n",
    "        \n",
    "        \n",
    "    def targeted_search(self, x, y):\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        if self.found == True: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                y_val = np.mean([i,j])\n",
    "                x_val = (np.mean(self.fit0))*y_val**2 + (np.mean(self.fit1))*y_val + (np.mean(self.fit2))\n",
    "                x_idx = np.where((((x_val - 10) < x)&(x < (x_val + 10))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    np.append(x_vals, x_window)\n",
    "                    np.append(y_vals, y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(x_vals) == 0: \n",
    "            self.found = False\n",
    "        return x_vals, y_vals, self.found\n",
    "    \n",
    "    def random_search(self, x, y, image):\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        if self.found == False: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                histogram = np.sum(image[j:i,:], axis=0)\n",
    "                if self == Right:\n",
    "                    peak = np.argmax(histogram[640:]) + 640\n",
    "                else:\n",
    "                    peak = np.argmax(histogram[:640])\n",
    "                x_idx = np.where((((peak - 25) < x)&(x < (peak + 25))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    x_vals.extend(x_window)\n",
    "                    y_vals.extend(y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(x_vals) > 0:\n",
    "            self.found = True\n",
    "        else:\n",
    "            y_vals = self.Y\n",
    "            x_vals = self.X\n",
    "        return x_vals, y_vals, self.found\n",
    "    \n",
    "    \n",
    "    def find_intercepts(self, polynomial):\n",
    "        bottom = polynomial[0]*720**2 + polynomial[1]*720 + polynomial[2]\n",
    "        top = polynomial[0]*0**2 + polynomial[1]*0 + polynomial[2]\n",
    "        return bottom, top\n",
    "    \n",
    "    def sort_values(self, x_vals, y_vals):\n",
    "        sorted_index = np.argsort(y_vals)\n",
    "        sorted_y_vals = y_vals[sorted_index]\n",
    "        sorted_x_vals = x_vals[sorted_index]\n",
    "        return sorted_x_vals, sorted_y_vals\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#to initialize values and later pass through for next frame\n",
    "Left = Line()\n",
    "Right = Line()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for Video Processing\n",
    "def process_image(image):\n",
    "    \n",
    "    #calibrate and undistory image based on camera parameters\n",
    "    undistorted = undistort(image)\n",
    "    \n",
    "    #prespective transformation is applied to get birds eye view\n",
    "    warped_image, m_inv = transform_prespective(undistorted)\n",
    "\n",
    "    #thresholded image to extract lane lines from frame\n",
    "    thresholded = threshold_video_hard(warped_image)\n",
    "    \n",
    "    # Detect the lane pixels in the image\n",
    "    left_y, left_x, right_y, right_x =  find_lane_pixels_vid(thresholded)\n",
    "            \n",
    "    # Find left & right polynomial fit based on detected pixels\n",
    "    right_fitx, left_fitx = fit_polynomial_vid(left_y, left_x, right_y, right_x)\n",
    "\n",
    "    # Calculate radius of curvature for each lane (in meters)\n",
    "    left_curve_radius, right_curve_radius = curve_radius(undistorted.shape[0]-1)\n",
    "    avg_radius = (left_curve_radius + right_curve_radius)/2\n",
    "    \n",
    "    ##highlight lane area \n",
    "    out_img = Lane_Area_Vid(thresholded, undistorted, left_fitx, right_fitx, m_inv,avg_radius)\n",
    "    \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video Output_challenge_cruv.mp4\n",
      "[MoviePy] Writing video Output_challenge_cruv.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/485 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/485 [00:00<06:45,  1.19it/s]\u001b[A\n",
      "  0%|          | 2/485 [00:01<06:46,  1.19it/s]\u001b[A\n",
      "  1%|          | 3/485 [00:02<06:43,  1.19it/s]\u001b[A\n",
      "  1%|          | 4/485 [00:03<06:38,  1.21it/s]\u001b[A\n",
      "100%|██████████| 485/485 [07:05<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: Output_challenge_cruv.mp4 \n",
      "\n",
      "CPU times: user 6min 17s, sys: 1.17 s, total: 6min 18s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "video_output = 'Output_challenge_cruv.mp4'\n",
    "clip = VideoFileClip('challenge_video.mp4')\n",
    "\n",
    "output_clip = clip.fl_image(process_image)\n",
    "%time output_clip.write_videofile(video_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
